# Distributed Queue System

A modular, in-memory distributed queue system similar to Kafka, built with C# and .NET 9.0.

> **ğŸ“ Ultra-Clean Structure**: All files organized into 4 main folders. See [docs/FOLDER_STRUCTURE.md](docs/FOLDER_STRUCTURE.md) for details.

## ğŸš€ Quick Start

### Deploy to Podman Desktop (Recommended)
```powershell
cd scripts
.\deploy-podman.ps1
```

### Run Locally (Development)
```powershell
cd scripts
.\start.ps1
```

### Test the Deployment
```powershell
cd scripts
.\test-api.ps1
```

## ğŸ“ Project Structure

```
DistributedQueue/
â”œâ”€â”€ ğŸ“ src/                          # Source code
â”‚   â”œâ”€â”€ DistributedQueue.Core/       # Core domain models and services
â”‚   â”œâ”€â”€ DistributedQueue.Api/        # REST API with Swagger
â”‚   â””â”€â”€ DistributedQueue.Kafka/      # Confluent Kafka integration
â”‚
â”œâ”€â”€ ğŸ“ scripts/                      # PowerShell scripts
â”‚   â”œâ”€â”€ deploy-podman.ps1            # ğŸ³ Deploy to Podman
â”‚   â”œâ”€â”€ start.ps1                    # ğŸ’» Run locally
â”‚   â”œâ”€â”€ test-api.ps1                 # ğŸ§ª Test the API
â”‚   â”œâ”€â”€ view-logs.ps1                # ğŸ“Š View container logs
â”‚   â””â”€â”€ stop-podman.ps1              # ğŸ›‘ Stop container
â”‚
â”œâ”€â”€ ğŸ“ docker/                       # Docker/Podman files
â”‚   â”œâ”€â”€ Dockerfile                   # Multi-stage build config
â”‚   â”œâ”€â”€ docker-compose.yml           # Compose configuration
â”‚   â””â”€â”€ .dockerignore                # Build context exclusions
â”‚
â”œâ”€â”€ ğŸ“ docs/                         # All documentation
â”‚   â”œâ”€â”€ START_HERE.md                # â­ Quick start guide
â”‚   â”œâ”€â”€ INDEX.md                     # Complete documentation index
â”‚   â”œâ”€â”€ QUICK_REF.md                 # Quick reference card
â”‚   â”œâ”€â”€ FOLDER_STRUCTURE.md          # Detailed folder structure
â”‚   â”œâ”€â”€ ProblemStatement.md          # Original requirements
â”‚   â”œâ”€â”€ DEPLOY_README.md             # Deployment quick guide
â”‚   â”œâ”€â”€ PODMAN_DEPLOYMENT.md         # Full deployment guide
â”‚   â”œâ”€â”€ DEPLOYMENT_CHECKLIST.md      # Verification checklist
â”‚   â”œâ”€â”€ DEPLOYMENT_FLOW.md           # Visual flow diagrams
â”‚   â”œâ”€â”€ QUICKSTART.md                # Local development guide
â”‚   â”œâ”€â”€ API_EXAMPLES.md              # API usage examples
â”‚   â”œâ”€â”€ PROJECT_SUMMARY.md           # Project overview
â”‚   â”œâ”€â”€ STRUCTURE.md                 # Architecture details
â”‚   â”œâ”€â”€ EXTENSION_GUIDE.md           # How to extend
â”‚   â”œâ”€â”€ REORGANIZATION.md            # What changed
â”‚   â””â”€â”€ START.md                     # Visual summary
â”‚
â”œâ”€â”€ ğŸ“„ README.md                     # This file
â”œâ”€â”€ ğŸ“„ .gitignore                    # Git ignore rules
â””â”€â”€ ğŸ“„ DistributedQueue.sln          # Solution file
```

> **ğŸ“š All documentation**: See [docs/INDEX.md](docs/INDEX.md) for complete documentation index

## ğŸ—ï¸ Architecture

The solution consists of three main projects:

### 1. **DistributedQueue.Core** (Class Library)
Core domain models and business logic:
- **Models**: `Message`, `Topic`, `Producer`, `Consumer`, `ConsumerGroup`
- **Services**: 
  - `TopicManager` - Manages topic lifecycle
  - `ProducerManager` - Manages producers
  - `ConsumerManager` - Manages consumers and subscriptions
  - `ConsumerGroupManager` - Manages consumer groups
  - `MessageBroker` - Handles message publishing and consumption

### 2. **DistributedQueue.Api** (Web API)
REST API with the following controllers:
- `TopicsController` - Topic CRUD operations
- `ProducersController` - Producer management
- `ConsumersController` - Consumer management and subscriptions
- `MessagesController` - Message publishing
- `ConsumerGroupsController` - Consumer group management
- `DemoController` - Demonstration scenarios

### 3. **DistributedQueue.Kafka** (Class Library)
Confluent Cloud Kafka integration (ready for future use):
- `KafkaProducerService` - Kafka message publishing
- `KafkaConsumerService` - Kafka message consumption
- `KafkaSettings` - Configuration for Confluent Cloud

## âœ¨ Features

- âœ… **In-Memory Queue**: No file system dependency
- âœ… **Multiple Topics**: Support for multiple named topics
- âœ… **Multi-Producer/Consumer**: Multiple producers and consumers
- âœ… **Flexible Subscriptions**: Consumers can subscribe to multiple topics
- âœ… **Consumer Groups**: Support for consumer groups with load balancing
- âœ… **Thread-Safe**: Concurrent message production and consumption
- âœ… **REST API**: Full RESTful API for all operations
- âœ… **Plug & Play**: Easy to add/remove producers, consumers, and topics
- âœ… **Kafka-Ready**: Prepared for Confluent Cloud Kafka integration

## ğŸš€ Getting Started

### Prerequisites
- .NET 9.0 SDK or later
- Podman Desktop (for containerized deployment)

### Option 1: Deploy to Podman (Recommended)
```bash
cd scripts
.\deploy-podman.ps1
```
Access at: http://localhost:8080/swagger

### Option 2: Run Locally
```bash
cd scripts
.\start.ps1
```
Access at: https://localhost:5001/swagger

## ğŸ“š Documentation

All documentation is in the `docs/` folder:

- **[docs/START_HERE.md](docs/START_HERE.md)** - â­ Best place to start!
- **[docs/INDEX.md](docs/INDEX.md)** - Complete documentation index
- **[docs/QUICK_REF.md](docs/QUICK_REF.md)** - Quick reference card
- **[docs/DEPLOY_README.md](docs/DEPLOY_README.md)** - Quick deployment guide
- **[docs/PODMAN_DEPLOYMENT.md](docs/PODMAN_DEPLOYMENT.md)** - Complete Podman guide
- **[docs/QUICKSTART.md](docs/QUICKSTART.md)** - Local development guide
- **[docs/API_EXAMPLES.md](docs/API_EXAMPLES.md)** - API usage examples
- **[docs/EXTENSION_GUIDE.md](docs/EXTENSION_GUIDE.md)** - How to extend the system

## ğŸ§ª Running the Demo

### Using Podman
```powershell
cd scripts
.\deploy-podman.ps1
.\test-api.ps1
.\view-logs.ps1
```

### Using Swagger UI
1. Navigate to http://localhost:8080/swagger (Podman) or https://localhost:5001/swagger (local)
2. Find the **Demo** section
3. Execute `POST /api/demo/run-scenario`
4. Check console/logs for output:
   ```
   consumer1 received Message 1
   consumer2 received Message 2
   consumer3 received Message 3
   ...
   ```

## ğŸ“ API Endpoints

### Topics
- `POST /api/topics` - Create a topic
- `GET /api/topics` - Get all topics
- `GET /api/topics/{topicName}` - Get topic details
- `DELETE /api/topics/{topicName}` - Delete a topic

### Producers
- `POST /api/producers` - Create a producer
- `GET /api/producers` - Get all producers
- `GET /api/producers/{producerId}` - Get producer details
- `DELETE /api/producers/{producerId}` - Delete a producer

### Consumers
- `POST /api/consumers` - Create a consumer
- `GET /api/consumers` - Get all consumers
- `GET /api/consumers/{consumerId}` - Get consumer details
- `POST /api/consumers/subscribe` - Subscribe consumer to topic
- `POST /api/consumers/{consumerId}/start` - Start consumer
- `POST /api/consumers/{consumerId}/stop` - Stop consumer
- `DELETE /api/consumers/{consumerId}` - Delete a consumer

### Messages
- `POST /api/messages/publish` - Publish a message to a topic

### Consumer Groups
- `POST /api/consumergroups` - Create a consumer group
- `GET /api/consumergroups` - Get all consumer groups
- `GET /api/consumergroups/{groupName}` - Get group details
- `DELETE /api/consumergroups/{groupName}` - Delete a group

### Demo
- `POST /api/demo/run-scenario` - Run the demonstration scenario
- `POST /api/demo/cleanup` - Clean up all resources

## ğŸ¯ Demo Scenario

Run the built-in demo scenario that matches the problem statement:

### Using Test Script
```bash
cd scripts
.\test-api.ps1
```

### Using curl
```bash
curl -X POST http://localhost:8080/api/demo/run-scenario
```

### Using PowerShell
```powershell
Invoke-WebRequest -Uri http://localhost:8080/api/demo/run-scenario -Method POST
```

This will:
1. Create 2 topics (topic1, topic2)
2. Create 2 producers (producer1, producer2)
3. Create 5 consumers (consumer1-5)
4. Subscribe all consumers to topic1
5. Subscribe consumers 1, 3, 4 to topic2
6. Publish messages as specified
7. Display consumption logs

**Check the console output** to see messages like:
```
consumer1 received Message 1
consumer2 received Message 2
consumer3 received Message 3
...
```

## ğŸ§ª Example Usage

### Create a Topic
```bash
POST /api/topics
{
  "topicName": "my-topic"
}
```

### Create a Producer
```bash
POST /api/producers
{
  "producerId": "producer1",
  "name": "My Producer"
}
```

### Create a Consumer with Consumer Group
```bash
POST /api/consumers
{
  "consumerId": "consumer1",
  "name": "My Consumer",
  "consumerGroup": "group1"
}
```

### Subscribe Consumer to Topic
```bash
POST /api/consumers/subscribe
{
  "consumerId": "consumer1",
  "topicName": "my-topic"
}
```

### Start Consumer
```bash
POST /api/consumers/consumer1/start
```

### Publish a Message
```bash
POST /api/messages/publish
{
  "producerId": "producer1",
  "topicName": "my-topic",
  "content": "Hello, World!"
}
```

## ğŸ”„ Confluent Cloud Kafka Integration

The `DistributedQueue.Kafka` project is ready for Confluent Cloud integration. To use it:

1. Update `appsettings.json` with your Kafka credentials:
```json
{
  "KafkaSettings": {
    "BootstrapServers": "your-cluster.cloud.confluent.com:9092",
    "SaslUsername": "your-api-key",
    "SaslPassword": "your-api-secret",
    "GroupId": "distributed-queue-group"
  }
}
```

2. Register services in `Program.cs`:
```csharp
builder.Services.Configure<KafkaSettings>(builder.Configuration.GetSection("KafkaSettings"));
builder.Services.AddSingleton<IKafkaProducerService, KafkaProducerService>();
builder.Services.AddSingleton<IKafkaConsumerService, KafkaConsumerService>();
```

## ğŸ›ï¸ Design Principles

- **Separation of Concerns**: Clear separation between domain logic, services, and API
- **Dependency Injection**: All services are injected via DI
- **Thread Safety**: Concurrent collections and locking mechanisms
- **SOLID Principles**: Interface-based design, single responsibility
- **Extensibility**: Easy to add new features and integrations

## ğŸ“¦ Project Structure

```
DistributedQueue/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ DistributedQueue.Core/
â”‚   â”‚   â”œâ”€â”€ Models/
â”‚   â”‚   â”‚   â”œâ”€â”€ Message.cs
â”‚   â”‚   â”‚   â”œâ”€â”€ Topic.cs
â”‚   â”‚   â”‚   â”œâ”€â”€ Producer.cs
â”‚   â”‚   â”‚   â”œâ”€â”€ Consumer.cs
â”‚   â”‚   â”‚   â””â”€â”€ ConsumerGroup.cs
â”‚   â”‚   â””â”€â”€ Services/
â”‚   â”‚       â”œâ”€â”€ MessageBroker.cs
â”‚   â”‚       â”œâ”€â”€ TopicManager.cs
â”‚   â”‚       â”œâ”€â”€ ProducerManager.cs
â”‚   â”‚       â”œâ”€â”€ ConsumerManager.cs
â”‚   â”‚       â””â”€â”€ ConsumerGroupManager.cs
â”‚   â”œâ”€â”€ DistributedQueue.Api/
â”‚   â”‚   â”œâ”€â”€ Controllers/
â”‚   â”‚   â”‚   â”œâ”€â”€ TopicsController.cs
â”‚   â”‚   â”‚   â”œâ”€â”€ ProducersController.cs
â”‚   â”‚   â”‚   â”œâ”€â”€ ConsumersController.cs
â”‚   â”‚   â”‚   â”œâ”€â”€ MessagesController.cs
â”‚   â”‚   â”‚   â”œâ”€â”€ ConsumerGroupsController.cs
â”‚   â”‚   â”‚   â””â”€â”€ DemoController.cs
â”‚   â”‚   â”œâ”€â”€ DTOs/
â”‚   â”‚   â”‚   â””â”€â”€ Requests.cs
â”‚   â”‚   â””â”€â”€ Program.cs
â”‚   â””â”€â”€ DistributedQueue.Kafka/
â”‚       â”œâ”€â”€ Producers/
â”‚       â”‚   â””â”€â”€ KafkaProducerService.cs
â”‚       â”œâ”€â”€ Consumers/
â”‚       â”‚   â””â”€â”€ KafkaConsumerService.cs
â”‚       â””â”€â”€ Configuration/
â”‚           â””â”€â”€ KafkaSettings.cs
â””â”€â”€ DistributedQueue.sln
```

## ğŸ¨ Future Enhancements

- [ ] Add web-based GUI for management
- [ ] Implement message persistence
- [ ] Add metrics and monitoring
- [ ] Support for message filtering
- [ ] Dead letter queue support
- [ ] Message retry mechanisms
- [ ] Authentication and authorization
- [ ] Docker containerization
- [ ] Unit and integration tests

## ğŸ“„ License

This project is for demonstration and educational purposes.
